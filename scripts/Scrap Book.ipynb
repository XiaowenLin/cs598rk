{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf, SQLContext, HiveContext, StorageLevel\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.mllib.feature import HashingTF\n",
    "\n",
    "sc = SparkContext()\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Importing other Libraries\n",
    "from np_extractor import *\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "#from rake import *\n",
    "import json\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- asin: string (nullable = true)\n",
      " |-- helpful: array (nullable = true)\n",
      " |    |-- element: long (containsNull = true)\n",
      " |-- overall: double (nullable = true)\n",
      " |-- reviewText: string (nullable = true)\n",
      " |-- reviewTime: string (nullable = true)\n",
      " |-- reviewerID: string (nullable = true)\n",
      " |-- reviewerName: string (nullable = true)\n",
      " |-- summary: string (nullable = true)\n",
      " |-- unixReviewTime: long (nullable = true)\n",
      " |-- asin: string (nullable = true)\n",
      " |-- brand: string (nullable = true)\n",
      " |-- categories: array (nullable = true)\n",
      " |    |-- element: array (containsNull = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- imUrl: string (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      " |-- related: struct (nullable = true)\n",
      " |    |-- also_bought: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |    |-- also_viewed: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |    |-- bought_together: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |    |-- buy_after_viewing: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |-- salesRank: struct (nullable = true)\n",
      " |    |-- Arts, Crafts & Sewing: long (nullable = true)\n",
      " |    |-- Automotive: long (nullable = true)\n",
      " |    |-- Baby: long (nullable = true)\n",
      " |    |-- Beauty: long (nullable = true)\n",
      " |    |-- Camera &amp; Photo: long (nullable = true)\n",
      " |    |-- Cell Phones & Accessories: long (nullable = true)\n",
      " |    |-- Clothing: long (nullable = true)\n",
      " |    |-- Computers & Accessories: long (nullable = true)\n",
      " |    |-- Electronics: long (nullable = true)\n",
      " |    |-- Grocery & Gourmet Food: long (nullable = true)\n",
      " |    |-- Health & Personal Care: long (nullable = true)\n",
      " |    |-- Home &amp; Kitchen: long (nullable = true)\n",
      " |    |-- Home Improvement: long (nullable = true)\n",
      " |    |-- Industrial & Scientific: long (nullable = true)\n",
      " |    |-- Jewelry: long (nullable = true)\n",
      " |    |-- Kitchen & Dining: long (nullable = true)\n",
      " |    |-- Magazines: long (nullable = true)\n",
      " |    |-- Movies & TV: long (nullable = true)\n",
      " |    |-- Musical Instruments: long (nullable = true)\n",
      " |    |-- Office Products: long (nullable = true)\n",
      " |    |-- Patio, Lawn & Garden: long (nullable = true)\n",
      " |    |-- Pet Supplies: long (nullable = true)\n",
      " |    |-- Shoes: long (nullable = true)\n",
      " |    |-- Software: long (nullable = true)\n",
      " |    |-- Sports &amp; Outdoors: long (nullable = true)\n",
      " |    |-- Toys & Games: long (nullable = true)\n",
      " |    |-- Video Games: long (nullable = true)\n",
      " |    |-- Watches: long (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Read Data file in sparkSQL\n",
    "# reviews = sqlContext.read.json(\"../data/reviews_electronics5000.json\")\n",
    "# reviews.persist(storageLevel=StorageLevel.MEMORY_AND_DISK_SER)\n",
    "revDB = sqlContext.read.json(\"../data/reviews_electronics5000.json\")\n",
    "metadataDB = sqlContext.read.json(\"../data/meta_electronics.json\")\n",
    "fullData = revDB.join(metadataDB)\n",
    "fullData.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fullData.groupBy(fullData['categories']).count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Read Data file in sparkSQL\n",
    "#reviews = sqlContext.read.json(\"../data/reviews_electronics5000.json\")\n",
    "#reviews.persist(storageLevel=StorageLevel.MEMORY_AND_DISK_SER)\n",
    "\n",
    "num_part = 16\n",
    "revs = get_rdd('../data', 'reviews_electronics5000.json', num_part)\n",
    "rev_texts = revs.map(lambda x: (x['asin'], x['reviewText']))\n",
    "#rev_agg_texts = rev_texts.map(lambda (asin, text): (asin, [text])).reduceByKey(lambda x, y: x + y)\n",
    "allRevs = rev_texts.map(lambda (asin,text): text)\n",
    "#allRevs.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "metadata = get_rdd('../data','meta_electronics.json',num_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_file = open(\"../data/MergedStopList.txt\", \"r\")\n",
    "lines = text_file.readlines()\n",
    "stopwords = [\"\"]\n",
    "for line in lines:\n",
    "    if \"#\" not in line:\n",
    "        stopwords.append(line.strip())\n",
    "\n",
    "import nltk.corpus\n",
    "#stopwords.words('english')\n",
    "nltk_stopwords = nltk.corpus.stopwords.words('english')\n",
    "stopwords.extend(nltk_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Cleaning up\n",
    "counts = allRevs.flatMap(lambda line: line.split(\" \"))\n",
    "counts = counts.flatMap(lambda word: nltk.word_tokenize(word))\n",
    "counts = counts.map(lambda word: (word.lower(), 1)).reduceByKey(lambda a, b: a + b)\n",
    "counts = counts.filter(lambda x: len(x[0]) > 2)\n",
    "counts = counts.filter(lambda x: x[0].isalnum())\n",
    "filteredCounts = counts.filter(lambda x: x[0] not in stopwords)\n",
    "filteredCounts = filteredCounts.cache()\n",
    "#filteredCounts.sortBy(lambda (word, count): count)\n",
    "#countsDF = filteredCounts.toDF()\n",
    "#filteredCounts.toDF().sort(desc(\"_2\"))\n",
    "vocabulary = filteredCounts.map(lambda x : x[0]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hashingTF = HashingTF()\n",
    "tf = hashingTF.transform(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filteredCounts = filteredCounts.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "posTaggedWords = posTaggedWords.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'precise', 4),\n",
       " (u'gripped', 2),\n",
       " (u'nookt', 1),\n",
       " (u'grandkids', 5),\n",
       " (u'3gi', 1)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filteredCounts.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "posTaggedWords = filteredCounts.map(lambda (word,count): (word,nltk.pos_tag(word)[0][1],count))\n",
    "df = pd.DataFrame(posTaggedWords.collect())\n",
    "df.to_csv('../data/processed/posTaggedWords_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Syntax for NLTK\n",
    "#tokens = nltk.word_tokenize(text)\n",
    "#tagged = nltk.pos_tag(tokens)\n",
    "#from nltk.corpus import stopwords\n",
    "#stopwords.words('english')\n",
    "#nltk_stopwords = stopwords.words('english')\n",
    "#other_stopwords = \n",
    "#from nltk.corpus import wordnet as wn\n",
    "# words = data.flatMap(lambda x: nltk.word_tokenize(x))\n",
    "# print words.take(10)\n",
    "# pos_word = words.map(lambda x: nltk.pos_tag([x]))\n",
    "# print pos_word.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(395, 4258)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import lda\n",
    "import lda.datasets\n",
    "X = lda.datasets.load_reuters()\n",
    "vocab = lda.datasets.load_reuters_vocab()\n",
    "titles = lda.datasets.load_reuters_titles()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1, ..., 0, 0, 0],\n",
       "       [7, 0, 2, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ..., \n",
       "       [1, 0, 1, ..., 0, 0, 0],\n",
       "       [1, 0, 1, ..., 0, 0, 0],\n",
       "       [1, 0, 1, ..., 0, 0, 0]], dtype=int32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: british churchill sale million major letters west britain\n",
      "Topic 1: church government political country state people party against\n",
      "Topic 2: elvis king fans presley life concert young death\n",
      "Topic 3: yeltsin russian russia president kremlin moscow michael operation\n",
      "Topic 4: pope vatican paul john surgery hospital pontiff rome\n",
      "Topic 5: family funeral police miami versace cunanan city service\n",
      "Topic 6: simpson former years court president wife south church\n",
      "Topic 7: order mother successor election nuns church nirmala head\n",
      "Topic 8: charles prince diana royal king queen parker bowles\n",
      "Topic 9: film french france against bardot paris poster animal\n",
      "Topic 10: germany german war nazi letter christian book jews\n",
      "Topic 11: east peace prize award timor quebec belo leader\n",
      "Topic 12: n't life show told very love television father\n",
      "Topic 13: years year time last church world people say\n",
      "Topic 14: mother teresa heart calcutta charity nun hospital missionaries\n",
      "Topic 15: city salonika capital buddhist cultural vietnam byzantine show\n",
      "Topic 16: music tour opera singer israel people film israeli\n",
      "Topic 17: church catholic bernardin cardinal bishop wright death cancer\n",
      "Topic 18: harriman clinton u.s ambassador paris president churchill france\n",
      "Topic 19: city museum art exhibition century million churches set\n"
     ]
    }
   ],
   "source": [
    "X.sum()\n",
    "model = lda.LDA(n_topics=20, n_iter=1500, random_state=1)\n",
    "model.fit(X)  # model.fit_transform(X) is also available\n",
    "topic_word = model.topic_word_  # model.components_ also works\n",
    "n_top_words = 8\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    topic_words = np.array(vocab)[np.argsort(topic_dist)][:-(n_top_words+1):-1]\n",
    "    print('Topic {}: {}'.format(i, ' '.join(topic_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 3. output\n",
    "# import pandas as pd\n",
    "# df = pd.DataFrame(items_np.collect())\n",
    "# df.to_csv('data/processed/computers_kw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mylist = ['spam', 'ham', 'eggs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = ' '.join(mylist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spam ham eggs'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
